# ğŸ§  AutoRAG â€” Belge TabanlÄ± Cevaplama Sistemi (Docker + GUI SÃ¼rÃ¼mÃ¼)

**AutoRAG**, `.pdf`, `.docx`, `.txt`, `.md` ve `.zip` gibi dosyalarÄ± iÅŸleyerek anlamlÄ± parÃ§alara bÃ¶len, embeddingâ€™lerini Ã§Ä±karan, Qdrant vektÃ¶r veritabanÄ±na kaydeden ve Ollama LLM API Ã¼zerinden TÃ¼rkÃ§e sorulara doÄŸru ve kaynaklÄ± cevaplar veren modern bir **Retrieval-Augmented Generation (RAG)** sistemidir.

Yeni sÃ¼rÃ¼mle birlikte artÄ±k kullanÄ±cÄ± dostu **web arayÃ¼zÃ¼ (GUI)** Ã¼zerinden tÃ¼m iÅŸlemleri gerÃ§ekleÅŸtirebilirsiniz!

---

## ğŸ” NasÄ±l Ã‡alÄ±ÅŸÄ±r?

1. YÃ¼klenen dosya (tekil veya `.zip`) aÃ§Ä±lÄ±r, `.pdf`, `.docx`, `.txt`, `.md` belgeler ayrÄ±ÅŸtÄ±rÄ±lÄ±r.
2. CÃ¼mlelere ayrÄ±lma iÅŸlemi `Stanza` ile yapÄ±lÄ±r.
3. Segmentler, seÃ§ilen **embedding modeli** ile vektÃ¶rleÅŸtirilir.
4. Bu vektÃ¶rler **Qdrant** veritabanÄ±na kaydedilir.
5. KullanÄ±cÄ±nÄ±n sorusu embedlenir, Qdrantâ€™tan en yakÄ±n parÃ§alar getirilir.
6. Bu parÃ§alar promptâ€™a gÃ¶mÃ¼lerek seÃ§ilen **LLM modeli** ile cevap Ã¼retilir.

---

## ğŸ› ï¸ Teknik Detaylar

| BileÅŸen                  | Teknoloji / AÃ§Ä±klama |
|--------------------------|----------------------|
| **Dil Modelleri (LLM)**  | `mistral:instruct`, `gemma:2b`, `Phi-2` *(Ollama ile local Ã§alÄ±ÅŸÄ±r)* |
| **Embedding Modelleri**  | `sentence-transformers/distiluse-base-multilingual-cased-v1`<br>`sentence-transformers/distiluse-base-multilingual-cased-v2`<br>`Trendyol/TY-ecomm-embed-multilingual-base-v1.2.0` |
| **Parserlar**            | `unstructured`, `stanza`, `python-docx`, `pypdf` |
| **VektÃ¶r VeritabanÄ±**    | `Qdrant` |
| **ArayÃ¼z**               | `Gradio` tabanlÄ± web arayÃ¼z (localhost:7860) |
| **Docker OrtamÄ±**        | `docker-compose` ile izole ve hÄ±zlÄ± kurulum |

**Not:**  
KullanÄ±lan dil modelleri (LLM), TÃ¼rkÃ§e dilinde yeterli performans sergileyen, dÃ¼ÅŸÃ¼k parametreli ve localde Ã§alÄ±ÅŸtÄ±rÄ±labilir modellerden seÃ§ilmiÅŸtir. BÃ¼yÃ¼k ve daha baÅŸarÄ±lÄ± modeller yerine bu seÃ§enekler tercih edilmiÅŸtir Ã§Ã¼nkÃ¼ hedef, sistemin donanÄ±m dostu, hÄ±zlÄ± ve eriÅŸilebilir olmasÄ±dÄ±r.

---

## âš™ï¸ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma AdÄ±mlarÄ±

### ğŸ§© 1. Bu klasÃ¶rÃ¼ bilgisayarÄ±nÄ±za indirin

GitHubâ€™dan veya `.zip` olarak projeyi indirip Ã§Ä±kartÄ±n. KlasÃ¶r yapÄ±sÄ± ÅŸu ÅŸekilde olmalÄ±dÄ±r:

```
autorag-system/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ *.py
â””â”€â”€ data/
    â””â”€â”€ belgeler.zip   â† belgelerinizi buraya koyabilirsiniz (isteÄŸe baÄŸlÄ±)
```

### ğŸ³ 2. Docker imageâ€™ini oluÅŸturun

Terminali bu klasÃ¶rde aÃ§Ä±n ve aÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rarak Docker imageâ€™ini oluÅŸturun:

```bash
docker-compose build
```

> Bu iÅŸlem ilk seferde uzun sÃ¼rebilir. Gerekli Python kÃ¼tÃ¼phaneleri indirilecektir.

---

## ğŸš€ Sistemi BaÅŸlatma (GUI Modu)

ArtÄ±k tÃ¼m iÅŸlemler tarayÄ±cÄ± tabanlÄ± grafiksel arayÃ¼z (GUI) Ã¼zerinden yapÄ±labilmektedir.

### âœ… KullanÄ±cÄ±ya saÄŸlanan seÃ§enekler:

- ğŸ“„ Belge yÃ¼kleme (.pdf, .docx, .txt, .md, .zip)
- ğŸ” Soru sorma
- ğŸ’¡ Embedding modeli seÃ§imi
- ğŸ§  LLM modeli seÃ§imi
- ğŸ”¢ Top-K chunk sayÄ±sÄ± ayarÄ±

### BaÅŸlatmak iÃ§in:

```bash
docker-compose run --rm autorag
```

ArdÄ±ndan tarayÄ±cÄ±nÄ±zda ÅŸu adresi aÃ§Ä±n:

```
http://localhost:7860
```

---

## ğŸ§¾ Tam Komutlar Zinciri (Kopyala-YapÄ±ÅŸtÄ±r iÃ§in)

```bash
# 1. Projeyi bir klasÃ¶re Ã§Ä±karÄ±n
cd autorag-system

# 2. Docker image oluÅŸtur
docker-compose build

# 3. (Opsiyonel) Belgeleri data/ klasÃ¶rÃ¼ne kopyalayÄ±n
mv ~/Downloads/belgeler.zip ./data/

# 4. Sistemi baÅŸlatÄ±n (GUI arayÃ¼zÃ¼ iÃ§in tarayÄ±cÄ±nÄ±zda http://localhost:7860 adresini aÃ§Ä±n.)
docker-compose run --rm autorag

# 5. Ä°ÅŸiniz bittiÄŸinde sistemi kapatÄ±n
docker-compose down
```

---

## ğŸ§¼ KullanÄ±mÄ± Bitirdikten Sonra

```bash
docker-compose down
```

---


## ğŸ“¬ Ä°letiÅŸim

Bu projeyle ilgili bir sorun yaÅŸarsanÄ±z veya katkÄ± sunmak isterseniz lÃ¼tfen iletiÅŸime geÃ§in.

Â© 2025 AutoRAG | TÃ¼rkÃ§e RAG sistemleri iÃ§in aÃ§Ä±k kaynaklÄ± Ã§Ã¶zÃ¼m ğŸ’¬
