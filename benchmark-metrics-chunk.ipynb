{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729f6f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\memo_\\AppData\\Local\\Temp\\ipykernel_7136\\466041145.py:12: UserWarning: Qdrant client version 1.14.3 is incompatible with server version 1.12.6. Major versions should match and minor version difference must not exceed 1. Set check_compatibility=False to skip version check.\n",
      "  return QdrantClient(\n",
      "C:\\Users\\memo_\\AppData\\Local\\Temp\\ipykernel_7136\\466041145.py:35: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  results = client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Sosyalist İktidar Partisi'nin adı ne zaman ve ne olarak değişmiştir?\n",
      "Recall: 1 | EIR: 0.0273 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Recep Tayyip Erdoğan kimdir?\n",
      "Recall: 1 | EIR: 0.0180 | nDCG@5: 0.4693\n",
      "\n",
      "🔍 Arkeoloji nedir?\n",
      "Recall: 1 | EIR: 0.0202 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Enis Batur kimdir?\n",
      "Recall: 1 | EIR: 0.0144 | nDCG@5: 0.6131\n",
      "\n",
      "🔍 Laparoskopi nedir?\n",
      "Recall: 1 | EIR: 0.0717 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 20. yüzyıl hangi tarih aralığını kapsar?\n",
      "Recall: 0 | EIR: 0.0196 | nDCG@5: 0.0000\n",
      "\n",
      "🔍 1944 nedir?\n",
      "Recall: 1 | EIR: 0.1200 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Erzurum neresidir?\n",
      "Recall: 1 | EIR: 0.0077 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Ekonomide esneklik (elastikiyet) ne anlama gelir?\n",
      "Recall: 1 | EIR: 0.0289 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Çankırı nerede bulunur?\n",
      "Recall: 1 | EIR: 0.0086 | nDCG@5: 0.5000\n",
      "\n",
      "🔍 Bulgaristan nerede yer alır?\n",
      "Recall: 1 | EIR: 0.0096 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Maldivler nerede bulunur ve kaç adadan oluşur?\n",
      "Recall: 1 | EIR: 0.0176 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Jeremy Bentham kimdir?\n",
      "Recall: 1 | EIR: 0.0107 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Gelir dağılımı neyi gösterir?\n",
      "Recall: 1 | EIR: 0.0344 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Cebirin temel teoremi ne ile ilgilidir?\n",
      "Recall: 1 | EIR: 0.0082 | nDCG@5: 0.4307\n",
      "\n",
      "🔍 Otizm nedir?\n",
      "Recall: 1 | EIR: 0.0234 | nDCG@5: 0.6309\n",
      "\n",
      "🔍 İsveç nerede yer almaktadır?\n",
      "Recall: 1 | EIR: 0.0093 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Tifo nasıl bulaşan bir hastalıktır?\n",
      "Recall: 1 | EIR: 0.0147 | nDCG@5: 0.0000\n",
      "\n",
      "🔍 Karadeniz Bölgesi'nin coğrafi konumu nedir?\n",
      "Recall: 1 | EIR: 0.0156 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 La Gioconda ne anlama gelebilir?\n",
      "Recall: 0 | EIR: 0.0000 | nDCG@5: 0.0000\n",
      "\n",
      "🔍 Bilinç nedir?\n",
      "Recall: 1 | EIR: 0.0254 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Werner Heisenberg kimdir?\n",
      "Recall: 1 | EIR: 0.0122 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 La Paz hangi ülkenin yönetimsel başkentidir?\n",
      "Recall: 1 | EIR: 0.0184 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Şumnu nerede bulunmaktadır?\n",
      "Recall: 0 | EIR: 0.0000 | nDCG@5: 0.0000\n",
      "\n",
      "🔍 Işık veya görünür ışık nedir?\n",
      "Recall: 1 | EIR: 0.0090 | nDCG@5: 0.3869\n",
      "\n",
      "🔍 Meteoroit nedir?\n",
      "Recall: 1 | EIR: 0.0062 | nDCG@5: 0.6309\n",
      "\n",
      "🔍 Takvim-i Vekayi'nin özelliği nedir?\n",
      "Recall: 1 | EIR: 0.0107 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Ferhat Livaneli kimdir?\n",
      "Recall: 1 | EIR: 0.0087 | nDCG@5: 0.6131\n",
      "\n",
      "🔍 Bakırın kimyasal sembolü ve atom numarası nedir?\n",
      "Recall: 1 | EIR: 0.0121 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Enez nerenin ilçesidir?\n",
      "Recall: 1 | EIR: 0.0112 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Pro-feminizm ne anlama gelmektedir?\n",
      "Recall: 1 | EIR: 0.0162 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Object Pascal'ı hangi firma geliştirmiştir?\n",
      "Recall: 1 | EIR: 0.0082 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Sanat en genel anlamıyla nasıl tanımlanır?\n",
      "Recall: 1 | EIR: 0.0066 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Kale vuruşu nedir?\n",
      "Recall: 1 | EIR: 0.0053 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Stefan Zweig'in \"Satranç\" romanının konusu nedir?\n",
      "Recall: 1 | EIR: 0.0209 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Hava nedir?\n",
      "Recall: 1 | EIR: 0.0108 | nDCG@5: 0.6309\n",
      "\n",
      "🔍 Silvan, hangi ilin bir ilçesidir?\n",
      "Recall: 1 | EIR: 0.0320 | nDCG@5: 0.6309\n",
      "\n",
      "🔍 Cebelitarık'ın coğrafi konumu ve statüsü nedir?\n",
      "Recall: 1 | EIR: 0.0192 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Cebriyye fırkasının kader ve irade konusundaki görüşü Kaderiyye'den nasıl farklılaşır?\n",
      "Recall: 1 | EIR: 0.0099 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 G8 ülkeleri hangileridir ve dünya ekonomisinin ne kadarını temsil ederler?\n",
      "Recall: 1 | EIR: 0.0474 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Abdi İpekçi kimdir?\n",
      "Recall: 1 | EIR: 0.0212 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Karl Weierstrass kimdir?\n",
      "Recall: 0 | EIR: 0.0000 | nDCG@5: 0.0000\n",
      "\n",
      "🔍 Baki kelimesinin anlamı nedir?\n",
      "Recall: 1 | EIR: 0.2857 | nDCG@5: 1.0000\n",
      "\n",
      "🔍 Türkiye'deki başlıca rüzgârlar nasıl sınıflandırılır?\n",
      "Recall: 1 | EIR: 0.0069 | nDCG@5: 0.0000\n",
      "\n",
      "🔍 Raffaello Sanzio kimdir?\n",
      "Recall: 1 | EIR: 0.0280 | nDCG@5: 1.0000\n",
      "\n",
      "===== TOPLU SONUÇLAR =====\n",
      "Ortalama Recall: 0.9111\n",
      "Ortalama EIR: 0.0247\n",
      "Ortalama nDCG@5: 0.7675\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import os\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ------------------- Qdrant Bağlantısı -------------------\n",
    "\n",
    "def connect_qdrant():\n",
    "    return QdrantClient(\n",
    "        url=\"http://localhost:6333\",\n",
    "        prefer_grpc=False,\n",
    "        timeout=60.0\n",
    "    )\n",
    "\n",
    "# ------------------- Metin Yardımcıları -------------------\n",
    "\n",
    "def normalize_text(text):\n",
    "    return text.replace(\" \", \"\").lower()\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    return [s.strip() for s in re.split(r'(?<=[.!?])\\s+', text) if s.strip()]\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "# ------------------- Chunkları Getir -------------------\n",
    "\n",
    "def retrieve_chunks(collection_name, embed_model, query, k):\n",
    "    client = connect_qdrant()\n",
    "    vector = embed_model.encode([query], convert_to_numpy=True)[0].tolist()\n",
    "\n",
    "    results = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=vector,\n",
    "        limit=k,\n",
    "        with_payload=True\n",
    "    )\n",
    "\n",
    "    chunks = []\n",
    "    for hit in results:\n",
    "        chunks.append(hit.payload.get(\"original_text\", \"\"))\n",
    "    return chunks\n",
    "\n",
    "# ------------------- Recall -------------------\n",
    "\n",
    "def recall_metric(gt_sentence, chunks, use_contains=True):\n",
    "    gt = normalize_text(gt_sentence)\n",
    "    cleaned_chunks = [normalize_text(c) for c in chunks]\n",
    "\n",
    "    if use_contains:\n",
    "        return int(any(gt in chunk for chunk in cleaned_chunks))\n",
    "    else:\n",
    "        return int(any(gt == chunk for chunk in cleaned_chunks))\n",
    "\n",
    "# ------------------- EIR -------------------\n",
    "\n",
    "def eir_metric(gt_sentence, chunks):\n",
    "    gt_sentences = split_into_sentences(gt_sentence)\n",
    "    retrieved_text = \" \".join(chunks)\n",
    "    retrieved_sentences = split_into_sentences(retrieved_text)\n",
    "\n",
    "    total_words = sum(count_words(chunk) for chunk in chunks)\n",
    "    if total_words == 0:\n",
    "        return 0.0\n",
    "\n",
    "    matched_words = 0\n",
    "    for gt in gt_sentences:\n",
    "        gt_norm = normalize_text(gt)\n",
    "        for rt in retrieved_sentences:\n",
    "            if gt_norm in normalize_text(rt):\n",
    "                matched_words += count_words(gt)\n",
    "                break\n",
    "    return matched_words / total_words\n",
    "\n",
    "# ------------------- NDCG -------------------\n",
    "\n",
    "def ndcg_metric(gt_sentence, chunks, k):\n",
    "    gt_sentences = set(normalize_text(s) for s in split_into_sentences(gt_sentence))\n",
    "    relevance_scores = []\n",
    "\n",
    "    for chunk in chunks[:k]:\n",
    "        chunk_sentences = set(normalize_text(s) for s in split_into_sentences(chunk))\n",
    "        rel = int(any(gt in chunk_sentences for gt in gt_sentences))\n",
    "        relevance_scores.append(rel)\n",
    "\n",
    "    dcg = sum(rel / math.log2(i + 2) for i, rel in enumerate(relevance_scores))\n",
    "    idcg = sum(1 / math.log2(i + 2) for i in range(min(len(gt_sentences), k)))\n",
    "\n",
    "    return dcg / idcg if idcg else 0.0\n",
    "\n",
    "# ------------------- Ana Değerlendirme Döngüsü -------------------\n",
    "\n",
    "def evaluate_all(df, embed_model, top_k):\n",
    "    recall_total = eir_total = ndcg_total = 0\n",
    "    num_queries = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        source_collection = os.path.splitext(row['filename'])[0]  # Örn: wiki_03\n",
    "        question = row['question']\n",
    "        gt_sentence = row['sentence']\n",
    "\n",
    "        chunks = retrieve_chunks(\n",
    "        collection_name=\"wiki_combined\", \n",
    "        embed_model=embed_model,\n",
    "        query=question,\n",
    "        k=top_k\n",
    "        )\n",
    "\n",
    "        if not chunks:\n",
    "            print(f\"'{source_collection}' kaynaklı chunk alınamadı.\")\n",
    "            continue\n",
    "\n",
    "        recall = recall_metric(gt_sentence, chunks)\n",
    "        eir = eir_metric(gt_sentence, chunks)\n",
    "        ndcg = ndcg_metric(gt_sentence, chunks, k=top_k)\n",
    "\n",
    "        print(f\"\\n🔍 {question}\")\n",
    "        print(f\"Recall: {recall} | EIR: {eir:.4f} | nDCG@{top_k}: {ndcg:.4f}\")\n",
    "\n",
    "        recall_total += recall\n",
    "        eir_total += eir\n",
    "        ndcg_total += ndcg\n",
    "        num_queries += 1\n",
    "\n",
    "    print(\"\\n===== TOPLU SONUÇLAR =====\")\n",
    "    print(f\"Ortalama Recall: {recall_total / num_queries:.4f}\")\n",
    "    print(f\"Ortalama EIR: {eir_total / num_queries:.4f}\")\n",
    "    print(f\"Ortalama nDCG@{top_k}: {ndcg_total / num_queries:.4f}\")\n",
    "# ------------------- Kullanım -------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"C:\\\\Users\\\\memo_\\\\Desktop\\\\Projeler\\\\AutoRAG-End-to-End-RAG-Framework-with-Turkish-Embedding-Evaluation\\\\wiki_with_full_qa_random.csv\"\n",
    "    top_k = 5\n",
    "    nrows = 45\n",
    "    embed_model = SentenceTransformer(\"distiluse-base-multilingual-cased-v1\")\n",
    "\n",
    "    df = pd.read_csv(csv_path, nrows=nrows)\n",
    "    evaluate_all(df, embed_model, top_k)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
